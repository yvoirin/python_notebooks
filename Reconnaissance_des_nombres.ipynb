{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOs3jmm58ie7FoatOicmapK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yvoirin/python_notebooks/blob/main/Reconnaissance_des_nombres.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utiliser Jupyter Notebook et TensorFlow/Keras\n",
        "\n",
        "## Objectifs\n",
        "\n",
        "Le but est de pouvoir exécuter du code Python faisant appel à Keras/TensorFlow. On va entrainer un réseau sur les données MNIST (http://yann.lecun.com/exdb/mnist/) et \n",
        "ensuite présenter nos propres images.\n",
        "\n",
        "(réf. : http://robhardwick.me/ml/hello-world/)\n",
        "\n",
        "Dans Jupyter sur Azure TensorFlow et Keras libs sont déjà présentes."
      ],
      "metadata": {
        "id": "h9IEd5BS1A3h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vérifier l'installation\n",
        "\n",
        "Avec quelques instuctions, on peut vérifier l'installation."
      ],
      "metadata": {
        "id": "u8K63y-Q1LY7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5VNuYq00gUt",
        "outputId": "191dc42e-5057-46a9-b1f4-fb7554e520c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.11.0\n"
          ]
        }
      ],
      "source": [
        "import keras\n",
        "print(keras.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Préparation du jeu d'entrainement\n",
        "\n",
        "On prépare les jeux d'entrainement et de test\n",
        "\n",
        "En utilisant Keras, on importe les données d'entrainement"
      ],
      "metadata": {
        "id": "IGFHfXcd1PtI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist\n",
        "#keras will automatically downlhoad the dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONqCt3Va1S3t",
        "outputId": "0b30a0e6-ee88-4d99-cc28-c30268df275f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vérification du jeu\n",
        "\n",
        "On vérifie la lecture des jeux de données *(il est possible qu'il faudra exécuter 2 fois la cellule pour voir les figures)*"
      ],
      "metadata": {
        "id": "JymcqwvL1XzM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# on utilise matplotlib pour afficher les données\n",
        "%matplotlib inline\n",
        "# on importe les fonctions\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "#taille du jeu de données\n",
        "train_size = len(x_train)\n",
        "#génère un nombre aléatoire\n",
        "random.seed(49)\n",
        "# on va créer le graphique (4 graphes)\n",
        "# on va simplement afficher 4 images utilisées pour l'entrainement\n",
        "\n",
        "plt.subplot(221)\n",
        "plt.imshow(x_train[random.randint(0, train_size-1)], cmap=plt.get_cmap('gray'))\n",
        "plt.subplot(222)\n",
        "plt.imshow(x_train[random.randint(0, train_size-1)], cmap=plt.get_cmap('gray'))\n",
        "plt.subplot(223)\n",
        "plt.imshow(x_train[random.randint(0, train_size-1)], cmap=plt.get_cmap('gray'))\n",
        "plt.subplot(224)\n",
        "plt.imshow(x_train[random.randint(0, train_size-1)], cmap=plt.get_cmap('gray'))\n",
        "# show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "Cp-lHAv81dq1",
        "outputId": "def53c96-1394-46b4-90d8-6a8c16679225"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Préparation des données\n",
        "\n",
        "On envoie pas des images au réseau de neurone. On va simplement envoyer une ligne de pixels (1d) composée de tous les pixels de l'image.\n",
        "\n",
        "On va modifier les données en entrée pour avoir une seule ligne"
      ],
      "metadata": {
        "id": "1SCTg4uJ1h_b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# nombre des pixels\n",
        "num_pixels = x_train.shape[1] * x_train.shape[2]\n",
        "#on refait nos données d'entrainement en 1 lignes de 784 pixels\n",
        "x_train = x_train.reshape(x_train.shape[0], num_pixels) / 255\n",
        "x_test = x_test.reshape(x_test.shape[0], num_pixels) / 255"
      ],
      "metadata": {
        "id": "6XoFvapp1lKs"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "On va convertir les données (entrainement et test) pour obtenir en sortie du réseau des résultats de type catégories"
      ],
      "metadata": {
        "id": "F-1x3TTu1pYU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import np_utils\n",
        "# on souhaite avoir en sortie une activation selon le chiffre (0 à 9)\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)"
      ],
      "metadata": {
        "id": "Emx7fu5s1qz6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Construction du réseau\n",
        "\n",
        "On va construire le réseau (c'est inspiré du code de http://robhardwick.me/ml/hello-world/).\n",
        "\n",
        "On peut inventer le réseau que l'on souhaite. En fonction de notre connaissance dans l'IA, on peut faire varier les couches et le type de couches."
      ],
      "metadata": {
        "id": "6aRt9Rxv19jI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# on importe les libs\n",
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Lambda, Activation\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
        "num_classes = len(y_train[0])\n",
        "# on définit la succession des couches\n",
        "model = Sequential()\n",
        "model.add(Conv2D(filters=32, kernel_size=(5, 5), input_shape=(28, 28, 1)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n",
        "model.add(Conv2D(64, (5, 5)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1024))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))"
      ],
      "metadata": {
        "id": "O6_qDY6Z2AOe"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "On affiche le réseau"
      ],
      "metadata": {
        "id": "pSqKtaLb2E9J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i, layer in enumerate(model.layers):\n",
        "    print(i,layer.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pfh5jgLr2IAu",
        "outputId": "612067aa-e683-4358-96ba-2ba8420b0955"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 conv2d\n",
            "1 activation\n",
            "2 max_pooling2d\n",
            "3 conv2d_1\n",
            "4 activation_1\n",
            "5 max_pooling2d_1\n",
            "6 flatten\n",
            "7 dense\n",
            "8 dropout\n",
            "9 dense_1\n",
            "10 activation_2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "On construit le réseau"
      ],
      "metadata": {
        "id": "uSY-TYMg2MzK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "mz2K9s1w2OTY"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "On l'entraine (cette dernière opération peut prendre 20 min). Activer le GPU pour accélérer les choses."
      ],
      "metadata": {
        "id": "Xw4lUD5D2Ub0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "round = 10#nombre de tour pour l'apprentissage (3 signifie que l'on présente 3 fois le j\n",
        "#eu d'entrainement, on peut facilement augmenter ce nombre)\n",
        "# on présente 3 fois 200 exemples\n",
        "model.fit(x_train, y_train, validation_split=0.1, epochs=round, batch_size=200, verbose=\n",
        "2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "id": "8OU8bD7E2Xyq",
        "outputId": "b2bd96e2-e825-4fc2-9e6c-62bd657ddb48"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "270/270 - 75s - loss: 0.1927 - accuracy: 0.9395 - val_loss: 0.0534 - val_accuracy: 0.9865 - 75s/epoch - 278ms/step\n",
            "Epoch 2/10\n",
            "270/270 - 93s - loss: 0.0497 - accuracy: 0.9844 - val_loss: 0.0393 - val_accuracy: 0.9882 - 93s/epoch - 343ms/step\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-96181aa08409>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#eu d'entrainement, on peut facilement augmenter ce nombre)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# on présente 3 fois 200 exemples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m model.fit(x_train, y_train, validation_split=0.1, epochs=round, batch_size=200, verbose=\n\u001b[0m\u001b[1;32m      5\u001b[0m 2)\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1648\u001b[0m                         ):\n\u001b[1;32m   1649\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1651\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    910\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m       (concrete_function,\n\u001b[1;32m    133\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 134\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    135\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1745\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    376\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    379\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vérification de l'apprentissage\n",
        "\n",
        "On peut évaluer la précision sur le jeu de test."
      ],
      "metadata": {
        "id": "zhipQjYw2eBI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scores = model.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "print(\"Baseline Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "metadata": {
        "id": "6eX_oHXM2hqm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test sur nos données\n",
        "\n",
        "On va évaluer nos images avec le réseau entrainé"
      ],
      "metadata": {
        "id": "v3JdGSKr2oEW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing import image\n",
        "import glob\n",
        "import numpy as np\n",
        "#load the images\n",
        "images = sorted(glob.glob('numbers/*.jpg'))\n",
        "for filename in images:\n",
        "    img = image.load_img(filename, target_size=(28, 28))\n",
        "    img = img.convert('L')\n",
        "    x = image.img_to_array(img)\n",
        "    x = 255 - x\n",
        "    x = (x - x.min()) / (x.max() - x.min())\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    npimg = np.vstack([x])\n",
        "    classes = classes_x=np.argmax(model.predict(npimg),axis=1) \n",
        "    probas = model.predict(npimg)\n",
        "    print(\"Fichier %s est un %d (%.2f %%)\" % (filename, classes[0], 100*probas[0]\n",
        "    [classes[0]]))"
      ],
      "metadata": {
        "id": "hJG39ftU2lSy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "On affiche les images testées"
      ],
      "metadata": {
        "id": "3BitOQK62wqb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# on utilise matplotlib pour afficher les données\n",
        "%matplotlib inline\n",
        "\n",
        "# on importe les fonctions\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# on va créer le graphique (4 graphes)\n",
        "# on va simplement afficher 4 images utilisées pour l'entrainement\n",
        "plt.subplot(221)\n",
        "plt.imshow(image.load_img('numbers/0.jpg',  target_size=(28, 28)), cmap=plt.get_cmap('gray'))\n",
        "plt.subplot(222)\n",
        "plt.imshow(image.load_img('numbers/1.jpg',  target_size=(28, 28)), cmap=plt.get_cmap('gray'))\n",
        "plt.subplot(223)\n",
        "plt.imshow(image.load_img('numbers/2.jpg',  target_size=(28, 28)), cmap=plt.get_cmap('gray'))\n",
        "plt.subplot(224)\n",
        "plt.imshow(image.load_img('numbers/7.jpg',  target_size=(28, 28)), cmap=plt.get_cmap('gray'))\n",
        "# show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hmB6_EUe201n"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}